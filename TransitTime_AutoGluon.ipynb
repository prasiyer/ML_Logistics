{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Env: pipy335\n",
    "import pandas as pd\n",
    "import fastai as fastai\n",
    "import numpy as np\n",
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task\n",
    "from sklearn import metrics\n",
    "from fastai.tabular.transform import Categorify, FillMissing, Normalize, add_datepart\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT THE FILE WITH DATASET\n",
    "inpDf = pd.read_csv('/data2/home/prasannaiyer/Projects/TT_AG/Dataset/OTD_2019_PU.csv')\n",
    "inpDf = inpDf[(inpDf['Days Late']<20)&((inpDf['Location Type']=='Plant')\\\n",
    "    |(inpDf['Location Type']=='Port')|(inpDf['Location Type']=='Keen'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RENAME COLUMNS AS WELL AS SET DATATYPE OF DATE FEATURES  ###\n",
    "inpDf['Delivery_Date'] = pd.to_datetime(inpDf['Shipment End Date'])\n",
    "inpDf['Pickup_Date'] = pd.to_datetime(inpDf['First shipped date (first YT26 action) Date'])\n",
    "inpDf.rename(columns = {'Shipment Secure Resources Upd Dt':'Tender_Date'},inplace = True)\n",
    "inpDf['Tender_Date'] = pd.to_datetime(inpDf['Tender_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE NEW FEATURES\n",
    "### OutputTransitTime IS THE DEPENDENT VARIABLE\n",
    "### OD IS A FEATURE FOR OVER-DIMENTIONSAL SHIPMENTS\n",
    "inpDf['OutputTransitTime'] = (inpDf['Delivery_Date']-inpDf['Pickup_Date']).dt.days\n",
    "inpDf['OD'] = [1 if OD > 0 else 0 for OD in inpDf['Shipment OD Day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVE OUTLIERS BASED ON CRITERIA FROM EDA ###\n",
    "inpDf = inpDf[(inpDf['OutputTransitTime'] <16) & (inpDf['OutputTransitTime'] > 0)]\n",
    "inpDf = inpDf[(inpDf['Shipment Loaded Distance']>200) & (inpDf['Shipment Loaded Distance']<2501)]\n",
    "### DROP NULL VALUES OF DEPENDENT VARIABLE ###\n",
    "inpDf.dropna(subset=['OutputTransitTime'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DROP COLUMNS NOT NEEDED FOR PREDICTION ###\n",
    "inpDf.drop(['Shipment GID', 'Delivery Status','Shipment Source Location GID',\\\n",
    "    'Shipment Source Province Code','Shipment Destination Location GID',\\\n",
    "        'Shipment Destination Location Name', 'Shipment Destination City',\\\n",
    "            'Shipment Enroute Status Upd Dt','Vehicle Outbound Delivery tendered and accepted Date',\\\n",
    "                'First shipped date (first YT26 action) Date', 'Shipment End Date',\\\n",
    "                    'Expected Days to Deliver', 'Actual Days', 'Days Late','Year',\\\n",
    "                        'Month','Shipment OD Day','Pickup_Date','Delivery_Date'],\\\n",
    "                            inplace = True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "### CREATION OF NEW FEATURES FROM EXISTING DATE FEATURES ###\n",
    "inpDf = add_datepart(inpDf,'Tender_Date',drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SORT THE DATAFRAME ###\n",
    "### Next step is to split the data into training and testing dataset. \n",
    "### Since this data involves dates, dataset is sorted by the specific date feature. \n",
    "### This ensures that older data is used for training and later data is used in testing. \n",
    "### This is important as the model will be used to predict future values of the dependent variable\n",
    "inpDf = inpDf.sort_values(by=['Tender_Date'])\n",
    "inpDf = inpDf.drop(['Tender_Date'],axis=1)\n",
    "data_count = inpDf.shape[0]\n",
    "data_train_count = int(data_count*0.8)\n",
    "data_val_count = data_count - data_train_count\n",
    "train_data = inpDf[:data_train_count]\n",
    "test_data = inpDf[data_train_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColumn = 'OutputTransitTime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autogluon requires directories for saving the output\n",
    "modelDir = '/home/prasannaiyer/Projects/AGModel1'\n",
    "modelDir1 = '/home/prasannaiyer/Projects/AGModel2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER PARAMETERS FOR VARIOUS ML ALGORITHMS\n",
    "nn_options = { 'num_epochs': 10}\n",
    "#hyperparameters = {'NN': nn_options}\n",
    "problemType = 'regression'\n",
    "hyperparameters={'NN': {'num_epochs':20},'GBM': {'num_boost_round':1000},'CAT': {'iterations':10000},'RF': {'n_estimators':300},\\\n",
    "    'XT': {'n_estimators':300},'KNN': {},'custom': ['GBM']}\n",
    "\n",
    "hp1={'GBM': {'num_boost_round':10000},'CAT': {'iterations':10000},'RF': {'n_estimators':500},\\\n",
    "    'XT': {'n_estimators':500},'KNN': {},'custom': ['GBM']}\n",
    "\n",
    "time_limits = 2*60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "Preprocessing data ...\n",
      "\tData preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: root_mean_squared_error\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "/data2/prasannaiyer/envs/pipy335/lib/python3.7/imp.py:342: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  return _load(spec)\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t3.89s\t = Training runtime\n",
      "\t-2.3592\t = Validation root_mean_squared_error score\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t2.5s\t = Training runtime\n",
      "\t-2.4441\t = Validation root_mean_squared_error score\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t0.03s\t = Training runtime\n",
      "\t-2.7712\t = Validation root_mean_squared_error score\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t0.03s\t = Training runtime\n",
      "\t-2.9917\t = Validation root_mean_squared_error score\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t0.9s\t = Training runtime\n",
      "\t-2.179\t = Validation root_mean_squared_error score\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t7.33s\t = Training runtime\n",
      "\t-2.2007\t = Validation root_mean_squared_error score\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t2.15s\t = Training runtime\n",
      "\t-2.2049\t = Validation root_mean_squared_error score\n",
      "Fitting model: weighted_ensemble_l1 ...\n",
      "\t0.61s\t = Training runtime\n",
      "\t-2.1587\t = Validation root_mean_squared_error score\n",
      "AutoGluon training complete, total runtime = 23.68s ...\n",
      "Beginning AutoGluon training ...\n",
      "Preprocessing data ...\n",
      "\tData preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: root_mean_squared_error\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t23.2s\t = Training runtime\n",
      "\t-2.4153\t = Validation root_mean_squared_error score\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t17.67s\t = Training runtime\n",
      "\t-2.4423\t = Validation root_mean_squared_error score\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t0.87s\t = Training runtime\n",
      "\t-2.8317\t = Validation root_mean_squared_error score\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t0.82s\t = Training runtime\n",
      "\t-3.0046\t = Validation root_mean_squared_error score\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t6.02s\t = Training runtime\n",
      "\t-2.308\t = Validation root_mean_squared_error score\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t65.4s\t = Training runtime\n",
      "\t-2.2844\t = Validation root_mean_squared_error score\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t14.58s\t = Training runtime\n",
      "\t-2.3063\t = Validation root_mean_squared_error score\n",
      "Fitting model: weighted_ensemble_l1 ...\n",
      "\t1.86s\t = Training runtime\n",
      "\t-2.2551\t = Validation root_mean_squared_error score\n",
      "Fitting model: RandomForestRegressorMSE_STACKER_l1 ...\n",
      "\t34.17s\t = Training runtime\n",
      "\t-2.28\t = Validation root_mean_squared_error score\n",
      "Fitting model: ExtraTreesRegressorMSE_STACKER_l1 ...\n",
      "\t20.69s\t = Training runtime\n",
      "\t-2.2778\t = Validation root_mean_squared_error score\n",
      "Fitting model: KNeighborsRegressorUnif_STACKER_l1 ...\n",
      "\t0.91s\t = Training runtime\n",
      "\t-2.8318\t = Validation root_mean_squared_error score\n",
      "Fitting model: KNeighborsRegressorDist_STACKER_l1 ...\n",
      "\t0.84s\t = Training runtime\n",
      "\t-2.8927\t = Validation root_mean_squared_error score\n",
      "Fitting model: LightGBMRegressor_STACKER_l1 ...\n",
      "\t4.48s\t = Training runtime\n",
      "\t-2.2843\t = Validation root_mean_squared_error score\n",
      "Fitting model: CatboostRegressor_STACKER_l1 ...\n",
      "\t20.04s\t = Training runtime\n",
      "\t-2.258\t = Validation root_mean_squared_error score\n",
      "Fitting model: LightGBMRegressorCustom_STACKER_l1 ...\n",
      "\t14.43s\t = Training runtime\n",
      "\t-2.2897\t = Validation root_mean_squared_error score\n",
      "Fitting model: weighted_ensemble_l2 ...\n",
      "\t1.86s\t = Training runtime\n",
      "\t-2.2474\t = Validation root_mean_squared_error score\n",
      "AutoGluon training complete, total runtime = 228.39s ...\n"
     ]
    }
   ],
   "source": [
    "### OPTION 1: TRAIN ON INDIVIDUAL ML ALGORITHMS\n",
    "predModel = task.fit(train_data = train_data,label = labelColumn,hyperparameters = hp1,\\\n",
    "    output_directory = modelDir,problem_type = problemType)\n",
    "\n",
    "### OPTION 1: TRAIN AN ENSEMBLE MODEL\n",
    "predModel1 = task.fit(train_data = train_data,label = labelColumn,hyperparameters = hp1,\\\n",
    "    output_directory = modelDir1,problem_type = problemType,num_bagging_folds=5,stack_ensemble_levels=1)\n",
    "\n",
    "### PREDICT THE OUTPUT ON TEST DATA\n",
    "test_data_nolabel = test_data.drop(labels = [labelColumn],axis=1)\n",
    "\n",
    "predOutput = predModel.predict(test_data_nolabel)\n",
    "predOutputEnsemble = predModel1.predict(test_data_nolabel)\n",
    "\n",
    "### Calculate the root mean squared error\n",
    "x = math.sqrt(metrics.mean_squared_error(test_data[labelColumn], predOutput))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5416aadab73ce924726a1eb24fd374c8e7a47219aa155be681024fb1353bbb6c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('pipy135')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
